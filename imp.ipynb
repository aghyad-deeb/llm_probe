{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_n_activations=(tensor([[[ 0.8885, -2.3749,  1.0280,  ..., -1.2279, -0.7093, -1.1844],\n",
      "         [-0.6804,  0.3470,  0.9527,  ..., -0.5443,  0.5179,  1.7816],\n",
      "         [-3.2383,  3.1348,  1.2394,  ..., -1.9160, -0.2958,  1.9392],\n",
      "         [-0.5292, -0.1116,  0.8534,  ..., -2.3048,  1.9161,  0.3600]]],\n",
      "       grad_fn=<AddBackward0>), (tensor([[[[-0.3408,  0.8585, -0.1599,  ...,  1.1341, -0.1732,  0.1462],\n",
      "          [-0.5527, -6.2879,  0.0307,  ..., -3.8074,  0.5053,  2.4742],\n",
      "          [-0.4397, -4.9840,  0.9941,  ..., -4.2766, -0.5312,  3.0052],\n",
      "          [-0.7805, -5.6348,  0.1387,  ..., -4.5761,  0.1280,  1.1601]],\n",
      "\n",
      "         [[ 0.0537,  0.8649, -0.6301,  ..., -0.0349,  0.2855,  0.0174],\n",
      "          [ 1.1466, -0.9112,  0.0447,  ...,  2.1192, -0.5966, -0.5425],\n",
      "          [ 0.1043,  1.0286,  0.4789,  ...,  2.6325, -0.5215, -0.6294],\n",
      "          [ 0.8533,  0.3559,  2.3165,  ...,  3.1323,  0.7863, -0.6658]],\n",
      "\n",
      "         [[-0.3110,  0.1350, -0.9827,  ..., -0.3543, -0.0525, -0.1379],\n",
      "          [-0.2185,  0.2247,  2.6164,  ...,  0.9373,  0.6249,  0.3634],\n",
      "          [-0.7109, -0.1302,  4.4813,  ...,  0.8112, -0.9025,  0.8547],\n",
      "          [-0.7410,  0.8822,  2.3276,  ...,  0.2444, -0.7612,  0.2321]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3680,  0.0704, -0.0714,  ..., -0.0387,  0.2336,  0.0115],\n",
      "          [-3.0412, -0.0738,  2.1857,  ..., -0.1331, -0.6098, -0.5626],\n",
      "          [-1.0125, -0.6051,  1.3430,  ..., -2.7926, -0.0730, -1.3075],\n",
      "          [-2.5579,  1.2189,  1.1357,  ..., -1.7477,  0.5947,  1.5894]],\n",
      "\n",
      "         [[ 0.2022,  0.0638,  0.3363,  ...,  0.4135,  0.0099,  0.2160],\n",
      "          [ 1.7325,  0.7064,  0.3160,  ..., -1.3130,  0.3046,  0.4912],\n",
      "          [ 2.3287,  0.3712,  1.0461,  ..., -1.6479,  0.3070,  1.0580],\n",
      "          [ 2.7023, -0.1910,  1.0645,  ..., -1.1162,  0.2946, -0.0733]],\n",
      "\n",
      "         [[-3.0244,  0.5300,  0.5607,  ..., -0.9401,  0.3239,  0.1843],\n",
      "          [ 8.4203, -0.9956, -2.5435,  ...,  2.6581, -0.4121, -0.0762],\n",
      "          [ 8.4428, -0.9414, -2.6855,  ...,  2.4165, -0.5824, -0.7091],\n",
      "          [ 8.2836, -1.2820, -1.1812,  ...,  2.8901,  0.1684, -1.1148]]]],\n",
      "       grad_fn=<TransposeBackward0>), tensor([[[[ 4.3166e-02, -4.7600e-02,  1.1009e-02,  ..., -7.0881e-02,\n",
      "           -4.2999e-03, -8.4636e-02],\n",
      "          [-3.5658e-01,  2.1893e-01, -9.6843e-01,  ...,  2.3265e-01,\n",
      "           -3.7752e-01,  4.5318e-01],\n",
      "          [-6.9471e-01, -6.4691e-02, -8.1847e-01,  ..., -3.1951e-01,\n",
      "           -5.2380e-01,  2.0828e-01],\n",
      "          [-2.6777e-01,  3.6020e-01, -5.0201e-01,  ...,  4.7142e-01,\n",
      "           -1.7527e-02, -5.0005e-01]],\n",
      "\n",
      "         [[ 7.1009e-02,  1.7761e-02, -2.0939e-02,  ..., -3.1767e-02,\n",
      "            1.0801e-02, -1.8366e-03],\n",
      "          [-3.1515e-01,  1.0920e+00, -3.4832e-01,  ...,  1.0768e+00,\n",
      "            5.2221e-01, -4.9559e-01],\n",
      "          [ 2.2857e-01, -2.8422e-01,  3.2454e-01,  ...,  1.0880e+00,\n",
      "            5.9878e-02,  1.9046e-01],\n",
      "          [ 1.5610e+00,  9.9194e-01, -7.4274e-01,  ..., -1.7211e-01,\n",
      "            2.4672e-01,  8.1977e-01]],\n",
      "\n",
      "         [[ 8.1070e-02,  1.6610e-02, -5.7159e-03,  ...,  2.3920e-02,\n",
      "           -6.8031e-02, -6.0603e-02],\n",
      "          [ 5.7319e-01, -2.6054e-01,  3.5248e-01,  ..., -1.0454e+00,\n",
      "            6.8087e-01,  2.6963e-01],\n",
      "          [ 2.7718e-01, -1.8238e-01, -1.7844e-01,  ..., -1.2636e+00,\n",
      "            1.7937e+00,  5.7514e-01],\n",
      "          [ 1.8832e-01,  7.3504e-02,  1.8207e-01,  ..., -9.1643e-01,\n",
      "            3.6352e-01, -3.6446e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3873e-03,  2.8190e-02,  1.7482e-02,  ..., -8.7293e-02,\n",
      "           -1.8433e-02,  1.6530e-02],\n",
      "          [-1.0061e+00,  4.9955e-01, -1.8535e-01,  ..., -1.4775e-01,\n",
      "           -2.0186e-01,  4.9314e-01],\n",
      "          [-7.9316e-01, -1.3778e-01,  8.9214e-01,  ...,  8.8079e-01,\n",
      "            2.2728e-01,  5.0325e-02],\n",
      "          [-4.1667e-01, -9.0873e-01,  1.5446e-01,  ...,  2.5416e-01,\n",
      "            2.3188e-01,  8.9342e-02]],\n",
      "\n",
      "         [[ 4.5025e-02, -4.6948e-04,  3.0498e-02,  ...,  2.9410e-02,\n",
      "           -1.4206e-02,  1.2066e-03],\n",
      "          [ 2.7558e+00, -8.1957e-01, -1.8042e+00,  ...,  3.0614e-01,\n",
      "            6.4232e-01,  6.6298e-01],\n",
      "          [ 8.9905e-02, -1.1767e+00, -1.6811e+00,  ..., -6.9321e-01,\n",
      "           -8.4284e-02,  8.1665e-01],\n",
      "          [ 1.5381e+00,  9.1727e-02, -1.8258e+00,  ...,  5.3360e-01,\n",
      "           -1.5200e-01,  7.4465e-01]],\n",
      "\n",
      "         [[ 7.1175e-02, -2.0185e-01, -6.6236e-02,  ..., -3.5605e-02,\n",
      "            1.9385e-01, -4.7338e-02],\n",
      "          [-3.9107e-01, -5.3681e-01,  9.7281e-02,  ..., -1.8940e-01,\n",
      "           -5.0546e-01,  7.7949e-01],\n",
      "          [-2.1018e-01, -9.0214e-01, -1.9414e-01,  ..., -1.3842e-01,\n",
      "            1.3591e-01,  5.1484e-01],\n",
      "          [-8.3558e-01, -8.0318e-01,  1.6862e-01,  ..., -2.7358e-01,\n",
      "           -6.8025e-02,  1.0269e+00]]]], grad_fn=<TransposeBackward0>)))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GPT2LMHeadModel' object has no attribute 'h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 114\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Example with two different models\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     router \u001b[38;5;241m=\u001b[39m ActivationRouter(\n\u001b[1;32m    108\u001b[0m         model_a_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai-community/gpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m         model_b_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai-community/gpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m         layer_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m    111\u001b[0m         layer_m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[0;32m--> 114\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrouter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello, world!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrouter\u001b[38;5;241m.\u001b[39mlayer_n\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model_b_output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    116\u001b[0m           result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_n_activations\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[9], line 96\u001b[0m, in \u001b[0;36mActivationRouter.process_text\u001b[0;34m(self, input_text)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Take first element if layer_n_activations is a tuple\u001b[39;00m\n\u001b[1;32m     95\u001b[0m activations \u001b[38;5;241m=\u001b[39m layer_n_activations[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer_n_activations, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m layer_n_activations\n\u001b[0;32m---> 96\u001b[0m outputs_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_m\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_a_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs_a,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_n_activations\u001b[39m\u001b[38;5;124m\"\u001b[39m: layer_n_activations,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_b_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs_b\n\u001b[1;32m    102\u001b[0m }\n",
      "File \u001b[0;32m~/Documents/coding/llm_probes/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/coding/llm_probes/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 63\u001b[0m, in \u001b[0;36mActivationRouter._modify_model_b.<locals>.new_forward\u001b[0;34m(self, inputs_embeds, past_key_values, attention_mask, layer_m, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Process through remaining layers\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layer_m, num_layers):\n\u001b[0;32m---> 63\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m[i](hidden_states)\n\u001b[1;32m     65\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(hidden_states)\n\u001b[1;32m     66\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/Documents/coding/llm_probes/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPT2LMHeadModel' object has no attribute 'h'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List, Dict\n",
    "\n",
    "class ActivationRouter:\n",
    "    def __init__(self, model_a_name: str, model_b_name: str, layer_n: int, layer_m: int):\n",
    "        \"\"\"\n",
    "        Initialize two models and prepare for activation routing\n",
    "        \n",
    "        Args:\n",
    "            model_a_name: HuggingFace model name for first model\n",
    "            model_b_name: HuggingFace model name for second model\n",
    "            layer_n: Which layer to extract activations from in model A\n",
    "        \"\"\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Initialize Model A\n",
    "        self.model_a = AutoModelForCausalLM.from_pretrained(model_a_name)\n",
    "        self.tokenizer_a = AutoTokenizer.from_pretrained(model_a_name)\n",
    "        self.model_a.to(self.device)\n",
    "        \n",
    "        # Initialize Model B\n",
    "        self.model_b = AutoModelForCausalLM.from_pretrained(model_b_name)\n",
    "        self.tokenizer_b = AutoTokenizer.from_pretrained(model_b_name)\n",
    "        self.model_b.to(self.device)\n",
    "        \n",
    "        self.layer_n = layer_n\n",
    "        self.activation = None\n",
    "        \n",
    "        # Register hook to capture activations\n",
    "        self._register_activation_hook()\n",
    "\n",
    "        self.layer_m = layer_m\n",
    "        self._modify_model_b()\n",
    "    \n",
    "    def _register_activation_hook(self):\n",
    "        \"\"\"Register a forward hook on layer n of model A\"\"\"\n",
    "        def hook_fn(module, input, output):\n",
    "            self.activation = output\n",
    "        \n",
    "        # Get the specific transformer layer\n",
    "        target_layer = self.model_a.transformer.h[self.layer_n]\n",
    "        target_layer.register_forward_hook(hook_fn)\n",
    "    \n",
    "    def _modify_model_b(self):\n",
    "        \"\"\"Modify model B to allow injection at intermediate layer\"\"\"\n",
    "        def new_forward(self, inputs_embeds=None, past_key_values=None, attention_mask=None, layer_m=0, **kwargs):\n",
    "            # Get the original forward method\n",
    "            orig_forward = self.__class__.forward.__get__(self, self.__class__)\n",
    "            \n",
    "            # If we're not injecting activations, use normal forward pass\n",
    "            if inputs_embeds is None:\n",
    "                return orig_forward(self, inputs_embeds=inputs_embeds, past_key_values=past_key_values, \n",
    "                                 attention_mask=attention_mask, **kwargs)\n",
    "            \n",
    "            # Inject activations\n",
    "            hidden_states = inputs_embeds\n",
    "            layers = self.h if hasattr(self, \"h\") else self.transformer.h\n",
    "            num_layers = len(layers)\n",
    "            \n",
    "            # Process through remaining layers\n",
    "            for i in range(layer_m, num_layers):\n",
    "                hidden_states = self.h[i](hidden_states)\n",
    "            \n",
    "            hidden_states = self.ln_f(hidden_states)\n",
    "            logits = self.lm_head(hidden_states)\n",
    "            \n",
    "            return logits\n",
    "        \n",
    "        # Bind the new forward method to model B\n",
    "        import types\n",
    "        self.model_b.forward = types.MethodType(new_forward, self.model_b)\n",
    "    \n",
    "    def process_text(self, input_text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Process text through model A, capture activations, and feed to model B\n",
    "        \n",
    "        Args:\n",
    "            input_text: Input text to process\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing both model outputs and intermediate activations\n",
    "        \"\"\"\n",
    "        # Process through Model A\n",
    "        inputs_a = self.tokenizer_a(input_text, return_tensors=\"pt\").to(self.device)\n",
    "        outputs_a = self.model_a(**inputs_a)\n",
    "        \n",
    "        # Get activations from layer n (captured by hook)\n",
    "        layer_n_activations = self.activation\n",
    "        \n",
    "        # Process activations through Model B\n",
    "        # Note: You might need to add a projection layer here if the hidden dimensions don't match\n",
    "        print(f\"{layer_n_activations=}\")\n",
    "        # Take first element if layer_n_activations is a tuple\n",
    "        activations = layer_n_activations[0] if isinstance(layer_n_activations, tuple) else layer_n_activations\n",
    "        outputs_b = self.model_b(inputs_embeds=activations, layer_m=self.layer_m)\n",
    "        \n",
    "        return {\n",
    "            \"model_a_output\": outputs_a,\n",
    "            \"layer_n_activations\": layer_n_activations,\n",
    "            \"model_b_output\": outputs_b\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example with two different models\n",
    "    router = ActivationRouter(\n",
    "        model_a_name=\"openai-community/gpt2\",\n",
    "        model_b_name=\"openai-community/gpt2\",\n",
    "        layer_n=6,\n",
    "        layer_m=6,\n",
    "    )\n",
    "    \n",
    "    result = router.process_text(\"Hello, world!\")\n",
    "    print(f\"Shape of layer {router.layer_n} model_b_output:\", \n",
    "          result[\"layer_n_activations\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
